'''
单进程运行，时间久，预计大概66小时左右
import requests
from urllib.request import urlopen
from multiprocessing import Pool
import time
import urllib.request
import re
from requests_html import HTMLSession

file=open('d:\\1.txt')
file2=open('D:\\test.txt','w')
i=0
for line in file.readlines():
    i=i+1
    line=line.strip('\n')
    url='https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids='+str(line)
    data=urllib.request.urlopen(url).read()
    data=data.decode("utf-8")  
    file2.write(data)
    print(i)
file2.close()

'''

'''
多进程，速度快，缺点是会丢失大量数据，需要不断利用excel寻找遗漏的数据，大概1-2轮即可得到完整数据。时间大概6小时

import time
import requests
from concurrent import futures
import requests
from urllib.request import urlopen
import urllib3
from multiprocessing import Pool
import time
import requests
import urllib.request
import re

file=open('D:\\pubmed1.txt')
pmid=file.readlines()

def get_data(url):
    file2=open('D:\\test.txt','a')
    data=urllib.request.urlopen(url).read()
    data=data.decode("utf-8")
    file2.write(data)
    return 1

def get_url():
    url_list=[]
    for i in pmid:
        url='https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids='+str(i)
        url_list.append(url)
    return url_list
s=time.time()
urls=get_url()
executor = futures.ThreadPoolExecutor(max_workers=10)
fs=[]
i=0
for url in urls:
    f=executor.submit(get_data, url)
    fs.append(f)
    i=i+1
    print(i)
futures.wait(fs)

print(time.time()-s)

'''

'''
excel辅助多进程
使用countif函数即可，在此不赘述
